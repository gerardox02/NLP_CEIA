{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e1cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.utils import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy.special import softmax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b03ed",
   "metadata": {},
   "source": [
    "### Importamos el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44052faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>Me acompaña el mate amargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Tu cicatriz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Es tan fácil perder la razón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Aunque pueda parecerte un desatino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>El campeón tiene miedo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Alrededor paranoia y dolor, la moneda cayó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>estoy cansado de los que vienen de amigos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>No hay pájaros en el nido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Soy el soldado de tu lado malvado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>¿Para qué guardar rencor?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0\n",
       "848                  Me acompaña el mate amargo\n",
       "714                                 Tu cicatriz\n",
       "510                Es tan fácil perder la razón\n",
       "568          Aunque pueda parecerte un desatino\n",
       "803                      El campeón tiene miedo\n",
       "432  Alrededor paranoia y dolor, la moneda cayó\n",
       "828   estoy cansado de los que vienen de amigos\n",
       "391                   No hay pájaros en el nido\n",
       "121           Soy el soldado de tu lado malvado\n",
       "871                   ¿Para qué guardar rencor?"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('calamaro.txt', sep='/n', header=None)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8468df54",
   "metadata": {},
   "source": [
    "### Preprocesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4fd9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No me claves tus puñales por la espalda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Largo de la secuencia, incluye seq input + word output\n",
    "train_len = 4\n",
    "\n",
    "text = df.loc[1,0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6f570a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'me', 'claves', 'tus', 'puñales', 'por', 'la', 'espalda']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text_to_word_sequence(text) # entran oraciones -> salen vectores de N posiciones (tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720426a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['flaca'],\n",
       " ['no', 'me', 'claves', 'tus', 'puñales', 'por', 'la', 'espalda'],\n",
       " ['tan', 'profundo']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recorrer todas las filas y transformar las oraciones en secuencias de palabras\n",
    "sentence_tokens = []\n",
    "for _, row in df[:None].iterrows():\n",
    "    sentence_tokens.append(text_to_word_sequence(row[0]))\n",
    "    \n",
    "sentence_tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd684cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['no', 'me', 'claves', 'tus'],\n",
       " ['me', 'claves', 'tus', 'puñales'],\n",
       " ['claves', 'tus', 'puñales', 'por'],\n",
       " ['tus', 'puñales', 'por', 'la']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Código para hacer el desfasaje de las palabras según el train_len\n",
    "text_sequences = []\n",
    "for i in range(train_len, len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    text_sequences.append(seq)\n",
    "\n",
    "text_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e851f",
   "metadata": {},
   "source": [
    "### Tokenización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5756d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 4, 2, 1], [4, 2, 1, 3], [2, 1, 3, 5], [1, 3, 5, 7]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = Tokenizer() \n",
    "tok.fit_on_texts(text_sequences) \n",
    "\n",
    "# Convertimos las palabras a números\n",
    "# entran palabras -> salen números\n",
    "sequences = tok.texts_to_sequences(text_sequences)\n",
    "\n",
    "# Ahora sequences tiene los números \"ID\", largo 4\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64869048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de casos (doc) de entrada\n",
    "print(tok.document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac891e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de veces que aparece cada palabra\n",
    "print(len(tok.word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53a9faad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tus': 1, 'claves': 2, 'puñales': 3, 'me': 4, 'por': 5, 'no': 6, 'la': 7}\n"
     ]
    }
   ],
   "source": [
    "# El índice para cada palabra\n",
    "# El sistema las ordena de las más populares a las menos populares\n",
    "print(tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996cadcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'tus': 4, 'claves': 3, 'me': 2, 'no': 1, 'puñales': 3, 'por': 2, 'la': 1})\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de veces quea aparece cada palabra en cada \"documento\"\n",
    "# (1 documento = 1 caso de entrada)\n",
    "print(tok.word_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feb451d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              Flaca\n",
       "1            No me claves tus puñales por la espalda\n",
       "2                                       Tan profundo\n",
       "3                      No me duelen, no me hacen mal\n",
       "4                                              Lejos\n",
       "5                          En el centro de la tierra\n",
       "6                                Las raíces del amor\n",
       "7                            Donde estaban, quedarán\n",
       "8                             Entre el no me olvides\n",
       "9                 Me dejé nuestros abriles olvidados\n",
       "10                           En el fondo del placard\n",
       "11                           Del cuarto de invitados\n",
       "12                              Eran tiempos dorados\n",
       "13                                   Un pasado mejor\n",
       "14    Aunque casi me equivoco y te digo poco a poco:\n",
       "15             No me mientas, no me digas la verdad,\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vistazo a las primeras filas\n",
    "df.loc[:15,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b4a47e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flaca No me claves tus puñales por la espalda Tan profundo No me duelen, no me hacen mal Lejos En el centro de la tierra Las raíces del amor Donde estaban, quedarán Entre el no me olvides Me dejé nuestros abriles olvidados En el fondo del placard Del cuarto de invitados Eran tiempos dorados Un pasado mejor Aunque casi me equivoco y te digo poco a poco: No me mientas, no me digas la verdad, No te quedes callada, no levantes la voz, Ni me pidas perdón Aunque casi te confieso Que también he sido un perro compañero Un perro ideal que aprendió a ladrar Y a volver al hogar, para poder comer Flaca No me claves, tus puñales, por la espalda Tan profundo No me duelen, no me hacen mal Lejos En el centro de la tierra Las raíces del amor Donde estaban, quedaran Cuando no estás O me encuentro en otro lugar del mundo Cuando no estás Me equivoco cada medio segundo Cuando no estás La soledad me aconseja mal Cuando no estás No se abre el paracaídas y salto igual Y me pierdo en habitaciones vacías Cuando no estás, cuando no estás conmigo Cuando no estás La casa vacía pregunta: ¿Cuándo volverás? Y escribo versos crueles conmigo Cuando no estás Estoy esperando que vuelvas Cuando no estás Me paso el día contando minutos Cuando no estás O me pierdo en un laberinto oscuro Cuando no estás La soledad me aconseja mal Cuando no estás La casa vacía pregunta: ¿Cuándo volverás? Y escribo versos un poco crueles conmigo Cuando no estás Estoy esperando que vuelvas Cuando no estás La casa vacía pregunta: ¿Cuándo volverás? Y escribo versos crueles conmigo Cuando no estás Estoy esperando que vuelvas Cuando no estás Solo espero verte llegar por esa puerta Lo que ocurre cuando vuelvo es que te quiero más Estoy esperando que vuelvas Cuando no estás conmigo Cuando no estás conmigo Cuando no estás conmigo Hace frío y estoy lejos de casa Hace tiempo que estoy sentado sobre esta piedra Yo me pregunto ¿Para qué sirven las guerras? Tengo un cohete en el pantalón Vos estás tan fría, como la nieve a mi alrededor Vos estás tan blanca Y yo no sé qué hacer La otra noche, te esperé bajo la lluvia dos horas Mil horas, como un perro Y cuando llegaste, me miraste y me dijiste: Loco Estás mojado, ya no te quiero En el circo, vos ya sos una estrella Una estrella roja que todo se lo imagina Si te preguntan, vos no me conocías No, no Yo tengo un cohete en el pantalón Vos estás tan fría, como la nieve a mi alrededor Vos estás tan blanca Que yo no sé qué hacer Te esperé bajo la lluvia, no, no, no La otra noche, te esperé bajo la lluvia dos horas Mil horas, como un perro Y cuando llegaste, me miraste y me dijiste: Loco Estás mojado, ya no te quiero La otra noche, te esperé bajo la lluvia dos horas Mil horas, como un perro Y cuando llegaste, me miraste y me dijiste: Loco Estás mojado, ya no te quiero Soy vulnerable a tu lado más amable Soy carcelero de tu lado más grosero Soy el soldado de tu lado más malvado Y el arquitecto de tus lados incorrectos Soy propietario de tu lado más caliente Soy dirigente de tu'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenamos todos los rows en un solo valor\n",
    "corpus = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=0)[0]\n",
    "corpus[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c09cf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flaca',\n",
       " 'no',\n",
       " 'me',\n",
       " 'claves',\n",
       " 'tus',\n",
       " 'puñales',\n",
       " 'por',\n",
       " 'la',\n",
       " 'espalda',\n",
       " 'tan',\n",
       " 'profundo',\n",
       " 'no',\n",
       " 'me',\n",
       " 'duelen',\n",
       " 'no',\n",
       " 'me',\n",
       " 'hacen',\n",
       " 'mal',\n",
       " 'lejos',\n",
       " 'en']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformar el corpus a tokens\n",
    "tokens=text_to_word_sequence(corpus)\n",
    "# Vistazo general de los primeros tokens\n",
    "tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d611c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tokens en el corpus: 6058\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de tokens en el corpus:\", len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d648a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['flaca', 'no', 'me', 'claves'],\n",
       " ['no', 'me', 'claves', 'tus'],\n",
       " ['me', 'claves', 'tus', 'puñales'],\n",
       " ['claves', 'tus', 'puñales', 'por'],\n",
       " ['tus', 'puñales', 'por', 'la'],\n",
       " ['puñales', 'por', 'la', 'espalda'],\n",
       " ['por', 'la', 'espalda', 'tan'],\n",
       " ['la', 'espalda', 'tan', 'profundo'],\n",
       " ['espalda', 'tan', 'profundo', 'no'],\n",
       " ['tan', 'profundo', 'no', 'me'],\n",
       " ['profundo', 'no', 'me', 'duelen'],\n",
       " ['no', 'me', 'duelen', 'no'],\n",
       " ['me', 'duelen', 'no', 'me'],\n",
       " ['duelen', 'no', 'me', 'hacen'],\n",
       " ['no', 'me', 'hacen', 'mal'],\n",
       " ['me', 'hacen', 'mal', 'lejos'],\n",
       " ['hacen', 'mal', 'lejos', 'en'],\n",
       " ['mal', 'lejos', 'en', 'el'],\n",
       " ['lejos', 'en', 'el', 'centro'],\n",
       " ['en', 'el', 'centro', 'de']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Código para hacer el desfasaje de las palabras según el train_len\n",
    "text_sequences = []\n",
    "for i in range(train_len, len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    text_sequences.append(seq)\n",
    "    \n",
    "text_sequences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0993a29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[613, 1, 9, 356],\n",
       " [1, 9, 356, 117],\n",
       " [9, 356, 117, 357],\n",
       " [356, 117, 357, 14],\n",
       " [117, 357, 14, 5],\n",
       " [357, 14, 5, 358],\n",
       " [14, 5, 358, 52],\n",
       " [5, 358, 52, 202],\n",
       " [358, 52, 202, 1],\n",
       " [52, 202, 1, 9],\n",
       " [202, 1, 9, 359],\n",
       " [1, 9, 359, 1],\n",
       " [9, 359, 1, 9],\n",
       " [359, 1, 9, 360],\n",
       " [1, 9, 360, 80],\n",
       " [9, 360, 80, 162],\n",
       " [360, 80, 162, 11],\n",
       " [80, 162, 11, 2],\n",
       " [162, 11, 2, 361],\n",
       " [11, 2, 361, 3]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proceso de tokenización\n",
    "tok = Tokenizer() \n",
    "tok.fit_on_texts(text_sequences) \n",
    "\n",
    "# Convertimos las palabras a números\n",
    "# entran palabras -> salen números\n",
    "sequences = tok.texts_to_sequences(text_sequences)\n",
    "\n",
    "# Damos un vistazo\n",
    "sequences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a539e09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows del dataset: 6054\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de rows del dataset:\", len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb9555cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con numpy es muy fácil realizar el slicing de vectores\n",
    "ex = np.array([[1,2,3,4],[5,6,7,8]])\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e630a031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: (2, 4)\n",
      "Todos los elementos: [[1 2 3 4]\n",
      " [5 6 7 8]]\n",
      "Todos los elementos menos el último: [[1 2 3]\n",
      " [5 6 7]]\n"
     ]
    }
   ],
   "source": [
    "# Con numpy es muy fácil realizar el slicing de vectores\n",
    "print(\"Dimension:\", ex.shape)\n",
    "print(\"Todos los elementos:\", ex)\n",
    "print(\"Todos los elementos menos el último:\", ex[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "179fa0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[1 2 3]\n",
      " [5 6 7]]\n",
      "Target: [4 8]\n"
     ]
    }
   ],
   "source": [
    "input = ex[:,:-1] # todos los rows, menos la ultima col\n",
    "target = ex[:, -1] # última col de cada row\n",
    "\n",
    "print(\"Input:\", input)\n",
    "print(\"Target:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b9988a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6054, 3)\n",
      "(6054,)\n"
     ]
    }
   ],
   "source": [
    "arr_sequences = np.array(sequences)\n",
    "x_data = arr_sequences[:,:-1]\n",
    "y_data_int = arr_sequences[:,-1] # aún falta el oneHotEncoder\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1069d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'no',\n",
       " 2: 'el',\n",
       " 3: 'de',\n",
       " 4: 'que',\n",
       " 5: 'la',\n",
       " 6: 'y',\n",
       " 7: 'a',\n",
       " 8: 'te',\n",
       " 9: 'me',\n",
       " 10: 'se',\n",
       " 11: 'en',\n",
       " 12: 'un',\n",
       " 13: 'es',\n",
       " 14: 'por',\n",
       " 15: 'amor',\n",
       " 16: 'del',\n",
       " 17: 'puede',\n",
       " 18: 'mi',\n",
       " 19: 'quiero',\n",
       " 20: 'porque'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras del vocabulario\n",
    "resultado = {k: tok.index_word[k] for k in list(tok.index_word)[:20]}\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97cdefad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de palabras en el vocabulario\n",
    "vocab_size = len(tok.word_counts)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aad32d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6054, 1198)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_int_offset = y_data_int - 1\n",
    "y_data = to_categorical(y_data_int_offset, num_classes=vocab_size) \n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f7bd937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Largo de la secuencia de entrada\n",
    "input_seq_len = x_data.shape[1] \n",
    "input_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e4a8692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Largo del vector de salida --> vocab_size\n",
    "output_size = vocab_size\n",
    "output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199aa70",
   "metadata": {},
   "source": [
    "### Definición y entrenamiento del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53fe53ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 25)             29975     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 3, 256)           157696    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 256)            0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 3, 256)           394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 3, 128)           164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 3, 128)           98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3, 128)            0         \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1198)              20366     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 991,637\n",
      "Trainable params: 991,637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size+1, output_dim=25, input_length=input_seq_len))\n",
    "\n",
    "# Primera capa LSTM con 128 unidades\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Segunda capa LSTM con 128 unidades\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "# Tercera capa LSTM con 64 unidades\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "\n",
    "# Cuarta capa LSTM con 64 unidades\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Quinta capa LSTM con 64 unidades\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Capas densas\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Capa de salida\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb4c637a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "152/152 [==============================] - 14s 27ms/step - loss: 6.2384 - accuracy: 0.0285 - val_loss: 6.6201 - val_accuracy: 0.0372\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 5.5882 - accuracy: 0.0378 - val_loss: 6.9942 - val_accuracy: 0.0264\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.4328 - accuracy: 0.0384 - val_loss: 7.2988 - val_accuracy: 0.0264\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.3159 - accuracy: 0.0337 - val_loss: 7.4249 - val_accuracy: 0.0264\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.2118 - accuracy: 0.0370 - val_loss: 7.8796 - val_accuracy: 0.0215\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 5.1272 - accuracy: 0.0287 - val_loss: 8.3951 - val_accuracy: 0.0355\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0668 - accuracy: 0.0365 - val_loss: 8.5043 - val_accuracy: 0.0396\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.0219 - accuracy: 0.0343 - val_loss: 8.7366 - val_accuracy: 0.0347\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.9919 - accuracy: 0.0390 - val_loss: 9.0191 - val_accuracy: 0.0405\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 4.9563 - accuracy: 0.0365 - val_loss: 9.1689 - val_accuracy: 0.0306\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.9093 - accuracy: 0.0452 - val_loss: 9.9364 - val_accuracy: 0.0273\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8655 - accuracy: 0.0463 - val_loss: 10.3178 - val_accuracy: 0.0281\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.8092 - accuracy: 0.0529 - val_loss: 10.2498 - val_accuracy: 0.0339\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.7479 - accuracy: 0.0547 - val_loss: 11.0857 - val_accuracy: 0.0281\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.6823 - accuracy: 0.0628 - val_loss: 10.7653 - val_accuracy: 0.0264\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.5947 - accuracy: 0.0634 - val_loss: 11.5410 - val_accuracy: 0.0297\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.5245 - accuracy: 0.0702 - val_loss: 11.7811 - val_accuracy: 0.0339\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.4440 - accuracy: 0.0811 - val_loss: 11.2728 - val_accuracy: 0.0239\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.3736 - accuracy: 0.0861 - val_loss: 10.9469 - val_accuracy: 0.0248\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2743 - accuracy: 0.0993 - val_loss: 12.3311 - val_accuracy: 0.0231\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 4.2113 - accuracy: 0.1123 - val_loss: 12.4776 - val_accuracy: 0.0273\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.1473 - accuracy: 0.1121 - val_loss: 11.9632 - val_accuracy: 0.0372\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.0888 - accuracy: 0.1183 - val_loss: 13.6220 - val_accuracy: 0.0306\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 4.0065 - accuracy: 0.1278 - val_loss: 13.7575 - val_accuracy: 0.0314\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.9791 - accuracy: 0.1286 - val_loss: 13.9005 - val_accuracy: 0.0157\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.9255 - accuracy: 0.1414 - val_loss: 14.1157 - val_accuracy: 0.0248\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.8704 - accuracy: 0.1485 - val_loss: 14.7421 - val_accuracy: 0.0306\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.8156 - accuracy: 0.1538 - val_loss: 15.0529 - val_accuracy: 0.0231\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7726 - accuracy: 0.1631 - val_loss: 15.3837 - val_accuracy: 0.0198\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.7323 - accuracy: 0.1652 - val_loss: 15.5990 - val_accuracy: 0.0231\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6706 - accuracy: 0.1695 - val_loss: 14.7545 - val_accuracy: 0.0206\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6299 - accuracy: 0.1807 - val_loss: 17.0518 - val_accuracy: 0.0157\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.6081 - accuracy: 0.1753 - val_loss: 16.0950 - val_accuracy: 0.0140\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5517 - accuracy: 0.1856 - val_loss: 17.7259 - val_accuracy: 0.0330\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 3.5002 - accuracy: 0.1922 - val_loss: 17.9507 - val_accuracy: 0.0248\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.4827 - accuracy: 0.1966 - val_loss: 17.1964 - val_accuracy: 0.0239\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.4335 - accuracy: 0.2019 - val_loss: 17.8644 - val_accuracy: 0.0297\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3945 - accuracy: 0.2052 - val_loss: 17.9238 - val_accuracy: 0.0223\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3653 - accuracy: 0.2152 - val_loss: 17.9527 - val_accuracy: 0.0140\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.3329 - accuracy: 0.2199 - val_loss: 19.9915 - val_accuracy: 0.0165\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.2552 - accuracy: 0.2329 - val_loss: 20.6451 - val_accuracy: 0.0173\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.2435 - accuracy: 0.2216 - val_loss: 19.8755 - val_accuracy: 0.0116\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.1871 - accuracy: 0.2449 - val_loss: 21.5949 - val_accuracy: 0.0248\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.1736 - accuracy: 0.2366 - val_loss: 19.5385 - val_accuracy: 0.0198\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 3.1560 - accuracy: 0.2420 - val_loss: 20.4798 - val_accuracy: 0.0149\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.1308 - accuracy: 0.2492 - val_loss: 21.1260 - val_accuracy: 0.0190\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0926 - accuracy: 0.2501 - val_loss: 20.7559 - val_accuracy: 0.0198\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 3.0295 - accuracy: 0.2668 - val_loss: 21.6200 - val_accuracy: 0.0132\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.9704 - accuracy: 0.2775 - val_loss: 22.7774 - val_accuracy: 0.0223\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.9924 - accuracy: 0.2709 - val_loss: 22.0501 - val_accuracy: 0.0239\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.9373 - accuracy: 0.2785 - val_loss: 23.2924 - val_accuracy: 0.0149\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.9344 - accuracy: 0.2866 - val_loss: 22.6248 - val_accuracy: 0.0190\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8888 - accuracy: 0.2977 - val_loss: 22.9072 - val_accuracy: 0.0239\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.8566 - accuracy: 0.2998 - val_loss: 22.7057 - val_accuracy: 0.0248\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.8056 - accuracy: 0.3052 - val_loss: 22.6307 - val_accuracy: 0.0157\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.8310 - accuracy: 0.3050 - val_loss: 22.7874 - val_accuracy: 0.0264\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.7517 - accuracy: 0.3188 - val_loss: 24.1767 - val_accuracy: 0.0281\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.7652 - accuracy: 0.3188 - val_loss: 23.2958 - val_accuracy: 0.0231\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.7435 - accuracy: 0.3275 - val_loss: 24.4329 - val_accuracy: 0.0173\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.7130 - accuracy: 0.3337 - val_loss: 24.0028 - val_accuracy: 0.0239\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6610 - accuracy: 0.3329 - val_loss: 24.9664 - val_accuracy: 0.0273\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.6781 - accuracy: 0.3347 - val_loss: 25.0700 - val_accuracy: 0.0206\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6478 - accuracy: 0.3413 - val_loss: 24.7568 - val_accuracy: 0.0264\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6226 - accuracy: 0.3488 - val_loss: 25.5055 - val_accuracy: 0.0273\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.6350 - accuracy: 0.3403 - val_loss: 23.8021 - val_accuracy: 0.0239\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5869 - accuracy: 0.3529 - val_loss: 26.5432 - val_accuracy: 0.0281\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5578 - accuracy: 0.3568 - val_loss: 25.1514 - val_accuracy: 0.0149\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5705 - accuracy: 0.3508 - val_loss: 24.2709 - val_accuracy: 0.0239\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.5102 - accuracy: 0.3640 - val_loss: 24.9967 - val_accuracy: 0.0231\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.5167 - accuracy: 0.3682 - val_loss: 25.3756 - val_accuracy: 0.0190\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4888 - accuracy: 0.3758 - val_loss: 25.3493 - val_accuracy: 0.0273\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.4887 - accuracy: 0.3789 - val_loss: 25.3223 - val_accuracy: 0.0256\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 2s 15ms/step - loss: 2.4329 - accuracy: 0.3929 - val_loss: 25.8189 - val_accuracy: 0.0248\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4326 - accuracy: 0.3872 - val_loss: 25.2057 - val_accuracy: 0.0231\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4347 - accuracy: 0.3826 - val_loss: 25.3354 - val_accuracy: 0.0248\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3842 - accuracy: 0.3915 - val_loss: 26.6082 - val_accuracy: 0.0264\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3611 - accuracy: 0.3944 - val_loss: 27.8160 - val_accuracy: 0.0281\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.4025 - accuracy: 0.3886 - val_loss: 26.2981 - val_accuracy: 0.0206\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3277 - accuracy: 0.4099 - val_loss: 26.9033 - val_accuracy: 0.0347\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3556 - accuracy: 0.4020 - val_loss: 26.2419 - val_accuracy: 0.0157\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3606 - accuracy: 0.4006 - val_loss: 28.1554 - val_accuracy: 0.0215\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.3162 - accuracy: 0.4175 - val_loss: 27.4072 - val_accuracy: 0.0223\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.3399 - accuracy: 0.4099 - val_loss: 24.6141 - val_accuracy: 0.0306\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2825 - accuracy: 0.4154 - val_loss: 27.6506 - val_accuracy: 0.0314\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2729 - accuracy: 0.4181 - val_loss: 29.1266 - val_accuracy: 0.0264\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2441 - accuracy: 0.4161 - val_loss: 28.2586 - val_accuracy: 0.0248\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2185 - accuracy: 0.4278 - val_loss: 28.0157 - val_accuracy: 0.0322\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2257 - accuracy: 0.4355 - val_loss: 27.8782 - val_accuracy: 0.0289\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1747 - accuracy: 0.4390 - val_loss: 29.2966 - val_accuracy: 0.0347\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1931 - accuracy: 0.4388 - val_loss: 30.6209 - val_accuracy: 0.0264\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.1815 - accuracy: 0.4388 - val_loss: 28.2416 - val_accuracy: 0.0132\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2094 - accuracy: 0.4340 - val_loss: 28.1436 - val_accuracy: 0.0206\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.2159 - accuracy: 0.4346 - val_loss: 28.7274 - val_accuracy: 0.0264\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1461 - accuracy: 0.4514 - val_loss: 29.2593 - val_accuracy: 0.0239\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 2.1386 - accuracy: 0.4510 - val_loss: 29.6019 - val_accuracy: 0.0239\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.1163 - accuracy: 0.4454 - val_loss: 30.0599 - val_accuracy: 0.0190\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0458 - accuracy: 0.4656 - val_loss: 31.5146 - val_accuracy: 0.0215\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0898 - accuracy: 0.4574 - val_loss: 32.5049 - val_accuracy: 0.0206\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0476 - accuracy: 0.4700 - val_loss: 31.9882 - val_accuracy: 0.0314\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 2s 14ms/step - loss: 2.0268 - accuracy: 0.4768 - val_loss: 32.9871 - val_accuracy: 0.0248\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "hist = model.fit(x_data, y_data, epochs=100, validation_split=0.2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd65efa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a772f6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def model_response(human_text):\n",
    "\n",
    "    # Encodeamos\n",
    "    encoded = tok.texts_to_sequences([human_text])[0]\n",
    "    # Si tienen distinto largo\n",
    "    encoded = pad_sequences([encoded], maxlen=3, padding='pre')\n",
    "    \n",
    "    # Predicción softmax\n",
    "    y_hat = model.predict(encoded).argmax(axis=-1)\n",
    "\n",
    "    # Debemos buscar en el vocabulario la palabra\n",
    "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
    "    out_word = ''\n",
    "    for word, index in tok.word_index.items():\n",
    "        if index == y_hat:\n",
    "            out_word = word\n",
    "            break\n",
    "\n",
    "    # Agrego la palabra a la frase predicha\n",
    "    return human_text + ' ' + out_word\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=model_response,\n",
    "    inputs=[\"textbox\"],\n",
    "    outputs=\"text\",\n",
    "    layout=\"vertical\")\n",
    "\n",
    "iface.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c83ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model, tokenizer, seed_text, max_length, n_words):\n",
    "    \"\"\"\n",
    "        Exec model sequence prediction\n",
    "\n",
    "        Args:\n",
    "            model (keras): modelo entrenado\n",
    "            tokenizer (keras tokenizer): tonenizer utilizado en el preprocesamiento\n",
    "            seed_text (string): texto de entrada (input_seq)\n",
    "            max_length (int): máxima longitud de la sequencia de entrada\n",
    "            n_words (int): números de palabras a agregar a la sequencia de entrada\n",
    "        returns:\n",
    "            output_text (string): sentencia con las \"n_words\" agregadas\n",
    "    \"\"\"\n",
    "    output_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # Encodeamos\n",
    "        encoded = tokenizer.texts_to_sequences([output_text])[0]\n",
    "        # Si tienen distinto largo\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\n",
    "        # Predicción softmax\n",
    "        y_hat = model.predict(encoded).argmax(axis=-1)\n",
    "        # Vamos concatenando las predicciones\n",
    "        out_word = ''\n",
    "\n",
    "        # Debemos buscar en el vocabulario la palabra\n",
    "        # que corresopnde al indice (y_hat) predicho por le modelo\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == y_hat:\n",
    "                out_word = word\n",
    "                break\n",
    "\n",
    "        # Agrego las palabras a la frase predicha\n",
    "        output_text += ' ' + out_word\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11486974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No se puede vivir amor'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text='No se puede vivir'\n",
    "\n",
    "generate_seq(model, tok, input_text, max_length=4, n_words=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d8fe358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yo soy un loco que'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text='yo soy un'\n",
    "\n",
    "generate_seq(model, tok, input_text, max_length=3, n_words=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b1db18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcionalidades para hacer encoding y decoding\n",
    "\n",
    "def encode(text,max_length=3):\n",
    "    encoded = tok.texts_to_sequences([text])[0]\n",
    "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "    return encoded\n",
    "\n",
    "def decode(seq):\n",
    "    return tok.sequences_to_texts([seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ab8f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que selecciona candidatos para el beam search\n",
    "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp=2):\n",
    "\n",
    "    # colectar todas las probabilidades para la siguiente búsqueda\n",
    "    pred_large = []\n",
    "\n",
    "    for idx,pp in enumerate(pred):\n",
    "        pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
    "\n",
    "    pred_large = np.array(pred_large)\n",
    "\n",
    "    # criterio de selección\n",
    "    # idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
    "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo\n",
    "\n",
    "    # traducir a índices de token en el vocabulario\n",
    "    new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
    "                        np.array([idx_select%vocab_size]).T),\n",
    "                      axis=1)\n",
    "\n",
    "    # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
    "    return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
    "\n",
    "\n",
    "def beam_search(model,num_beams,num_words,input):\n",
    "\n",
    "    # first iteration\n",
    "\n",
    "    # encode\n",
    "    encoded = encode(input)\n",
    "\n",
    "    # first prediction\n",
    "    y_hat = np.squeeze(model.predict(encoded))\n",
    "\n",
    "    # get vocabulary size\n",
    "    vocab_size = y_hat.shape[0] \n",
    "\n",
    "    # initialize history\n",
    "    history_probs = [0]*num_beams\n",
    "    history_tokens = [encoded[0]]*num_beams\n",
    "\n",
    "    # select num_beams candidates\n",
    "    history_probs, history_tokens = select_candidates([y_hat],\n",
    "                                        num_beams,\n",
    "                                        vocab_size,\n",
    "                                        history_probs,\n",
    "                                        history_tokens) \n",
    "\n",
    "    # beam search loop\n",
    "    for i in range(num_words-1):\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for hist in history_tokens:\n",
    "\n",
    "        # actualizar secuencia de tokens\n",
    "            input_update = np.array([hist[i+1:]]).copy()\n",
    "\n",
    "        # predicción\n",
    "            y_hat = np.squeeze(model.predict(input_update)) \n",
    "\n",
    "            preds.append(y_hat)\n",
    "\n",
    "        history_probs, history_tokens = select_candidates(preds,\n",
    "                                                        num_beams,\n",
    "                                                        vocab_size,\n",
    "                                                        history_probs,\n",
    "                                                        history_tokens) \n",
    "\n",
    "    return history_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7287dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['quiero ser el único que dijo vientos']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción con beam search\n",
    "salidas = beam_search(model,num_beams=10, num_words=4, input=\"quiero ser el\")\n",
    "decode(salidas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167616b",
   "metadata": {},
   "source": [
    "### Conclusiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c31364",
   "metadata": {},
   "source": [
    "Se logró desarrollar un predictor de palabra siguiente, y así formar una secuencia más larga de palabras. Sin embargo, este no tiene tanta precisión, sobre todo en la validación.\n",
    "\n",
    "Si bien es cierto, los resultados no fueron los mejores, aún así se pudo demostrar la funcionalidad del modelo.\n",
    "Por ejemplo, usando la función 'generate_seq' con la secuencia 'No se puede vivir', se obtuvo una salida ''No se puede vivir amor', lo cual sí tiene bastante sentido, ya que la letra de la canción dice 'No se puede vivir del amor'. Así que si bien es cierto, no se obtuvo ser fiel al 100% a la letra, sí se consiguió que la palabra predicha sí guarde relación con la letra de la canción.\n",
    "\n",
    "Luego cuando se quiso predecir 2 palabras, se usó la entrada 'yo soy un', se obtuvo como salida 'yo soy un loco que', lo cual es tal cual la letra original de la canción la cual es 'yo soy un loco que se dio cuenta'\n",
    "\n",
    "Por último, al hacer la predicción con la función 'beam_search', se predijeron las 3 palabra siguientes. Se usó como input 'quiero ser el' y se esperaba obtener algo parecido a la letra 'quiero ser el único que te muerda la boca'. Y si bien es cierto no se obtuvo tal cual esa letra, sí se consiguieron las 2 palabras siguientes 'único que', pero luego se obtuvieron palabras que no guardaban relación con la letra de la canción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b5fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
