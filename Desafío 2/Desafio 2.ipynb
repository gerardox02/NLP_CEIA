{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde9ff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Gerardo\n",
      "[nltk_data]     Vilcamiza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Gerardo\n",
      "[nltk_data]     Vilcamiza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Gerardo\n",
      "[nltk_data]     Vilcamiza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Gerardo\n",
      "[nltk_data]     Vilcamiza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import gradio as gr\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9ce04",
   "metadata": {},
   "source": [
    "## 1. Obtención de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43027d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = urllib.request.urlopen('https://es.wikipedia.org/wiki/Central_Restaurante')\n",
    "html_content = html_content.read()\n",
    "\n",
    "parse_html = bs.BeautifulSoup(html_content, 'lxml')\n",
    "parrafos = parse_html.find_all('p')\n",
    "\n",
    "full_text = ''.join(para.text for para in parrafos).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32825c4d",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed68337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_clean_text(text):    \n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    pattern = r'\\[[0-9]*\\]'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    pattern = r'\\s+'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    #text = ''.join([c for c in text if c not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320b700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess_clean_text(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93970c04",
   "metadata": {},
   "source": [
    "## 3. Dividir el texto en sentencias y en palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4eddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 610\n"
     ]
    }
   ],
   "source": [
    "corpus = nltk.sent_tokenize(text)\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "print(\"Vocabulario:\", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fbaae2",
   "metadata": {},
   "source": [
    "## 4. Funciones de ayuda para limpiar y procesar el input del usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a530eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def perform_lemmatization(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
    "\n",
    "def get_processed_text(document):\n",
    "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2e5ba",
   "metadata": {},
   "source": [
    "## 5. Utilizar vectores TF-IDF y la similitud coseno construido con el corpus del artículo de wikipedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac7d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input, corpus):\n",
    "    response = ''\n",
    "    corpus.append(user_input)\n",
    "\n",
    "    word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text, stop_words=stopwords.words('spanish'))\n",
    "\n",
    "    all_word_vectors = word_vectorizer.fit_transform(corpus)\n",
    "\n",
    "    similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
    "    similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
    "    matched_vector = similar_vector_values.flatten()\n",
    "    matched_vector.sort()\n",
    "    vector_matched = matched_vector[-2]\n",
    "\n",
    "    if vector_matched == 0:\n",
    "        response = \"Disculpe, no lo entiendo o no cuento con esa respuesta\"\n",
    "    else:\n",
    "        response = corpus[similar_sentence_number]\n",
    "    \n",
    "    corpus.remove(user_input)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a88c5",
   "metadata": {},
   "source": [
    "## 6. Ensayar el sistema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfbd8281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gerardo Vilcamiza\\AppData\\Local\\Temp\\ipykernel_980\\3799335339.py:7: GradioDeprecationWarning: `layout` parameter is deprecated, and it has no effect\n",
      "  iface = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: quién es el chef principal?\n",
      "A: central restaurante es el restaurante principal del chef peruano virgilio martinez veliz y sirve como su taller en la investigacion y la integracion de insumos indigenas peruanos en la carta de comida del restaurante.\n",
      "Q: dónde se ubica Central?\n",
      "A: actualmente el restaurante se ubica en el distrito de barranco, en un espacio con un area aproximada de 3000 m2 que comparte con otras iniciativas del grupo como kjolle -el restaurante de la chef pia leon-, mayo bar y mater iniciativa, el centro de estudio biocultural del equipo de central.\n",
      "Q: dame ejemplos de los insumos que usan\n",
      "A: ejemplos de estos insumos son el cushuro, una cyanobacteria comestible de lagunas de altura; la arracacha, un tuberculo andino; y el paiche, un pez de agua dulce que vive en la cuenca del rio amazonas.\n",
      "Q: quién es la esposa de Virgilio?\n",
      "A: la chef de cocina es pia leon, esposa de martinez veliz.\n",
      "Q: en qué años fue catalogado como el mejor de Latinoamérica?\n",
      "A: ha sido catalogado cinco veces (2014, 2015, 2016, 2021 y 2022) como el mejor restaurante de latinoamerica, en 2022 como el segundo mejor del mundo en la lista the s.pellegrino the world's 50 best restaurants, elaborada por la revista restaurant, y como el mejor del mundo en 2023. la cocina de central restaurante se considera peruana contemporanea, y el fundador virgilio martinez veliz ha intentado redefinir la cocina peruana por la introduccion de insumos indigenas poco conocidos del peru.\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bot_response(human_text):\n",
    "    print(\"Q:\", human_text)\n",
    "    resp = generate_response(human_text.lower(), corpus)\n",
    "    print(\"A:\", resp)\n",
    "    return resp\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=bot_response,\n",
    "    inputs=[\"textbox\"],\n",
    "    outputs=\"text\",\n",
    "    layout=\"vertical\")\n",
    "\n",
    "iface.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba260e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
